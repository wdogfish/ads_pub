{"metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.2"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# K-Means"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As a first step, we will need to import the data from the `retail_ml_dataset.csv` data file that we constructed and exported on Day 1 (or the corresponding backup file that we have provided) into the variable **_X_** using the `read_csv()` function from `pandas` (`pd`). We also want to define the column that we are going to use as the row labels of the DataFrame; in this case, *CustomerID*. Once loaded, we can once again apply the `head()` function to preview the first 5 rows of our DataFrame. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import the data from the retail_ml_dataset.csv, \n", "\n", "customers_ml_data = pd.read_csv('data/online_retail_afterEDA.csv', index_col='CustomerID')\n", "customers_ml_data.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will start by looking specifically at numerical features. Below we list non binary features and separate this into a dataset called `customers`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["non_binary_cols = [\n", "    'balance', 'max_spent', 'mean_spent', \n", "    'min_spent', 'n_orders','total_items', \n", "    'total_refunded', 'total_spent' ]\n", "\n", "customers = customers_ml_data[non_binary_cols]\n", "customers.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's also import the data from `pca_scores.csv`. By now this should be easy! Let's call this `Xscores`. Set the index column to be `CustomerID`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import pca_scores.csv using pd.read_csv\n", "Xscores = pd.read_csv('data/pca_scores.csv', index_col='CustomerID')\n", "Xscores.head()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Clustering with K-Means\n", "\n", "K-means clustering is a method for finding clusters and cluster centroids (that is, the center point of a cluster) in a set of points. The K-means algorithm is quite simple and alternates between the two steps:\n", "\n", "1. for each centroid, identify the subset of training points that are closer to it than to any other centroid\n", "2. update the location of the centroid to match the points related to it\n", "\n", "These two steps are iterated until the centroids no longer move (significantly) or the assignments no longer change. Then, a new point $x$ can be assigned to the cluster of the closest prototype.\n", "\n", "### Learning Activity - Run K-Means with two features\n", "\n", "Isolate the features `mean_spent` and `max_spent`, then run the K-Means algorithm on the resulting dataset using K=2 and visualise the result. You will need:\n", "\n", "* to create an instance of `KMeans` with 2 clusters\n", "* fit this to the isolated features (via the `.fit` method)\n", "* look how it's doing by using by showing the assignment predicted (via the `.predict` method)\n", "\n", "This is the standard `sklearn` workflow for most of the algorithms."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.cluster import KMeans\n", "\n", "# Apply k-means with 2 clusters using a subset of features \n", "# (mean_spent and max_spent)\n", "\n", "kmeans = KMeans(n_clusters = 2)\n", "cust2  = customers[['mean_spent', 'max_spent']]\n", "kmeans.fit(cust2)\n", "cluster_assignment = kmeans.predict(cust2)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let us introduce a simple function to better visualise what's going on:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# This function generates a pairplot enhanced with the result of k-means\n", "def pairplot_cluster(df, cols, cluster_assignment):\n", "    \"\"\"\n", "    Input\n", "        df, dataframe that contains the data to plot\n", "        cols, columns to consider for the plot\n", "        cluster_assignments, cluster asignment returned \n", "        by the clustering algorithm\n", "    \"\"\"\n", "    # seaborn will color the samples according to the column cluster\n", "    df['cluster'] = cluster_assignment \n", "    sns.pairplot(df, vars=cols, hue='cluster')\n", "    df.drop('cluster', axis=1, inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And let's use it now to see how we did previously... (ignore the warnings if anything comes up)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualise the clusters using pairplot_cluster()\n", "pairplot_cluster(customers, ['mean_spent', 'max_spent'], cluster_assignment)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### What can you observe?\n", "\n", "* the separation between the two clusters is \"clean\" (the two clusters can be separated with a line)\n", "* one cluster contains customers with low spendings, the other one with high spendings"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Test Activity - Run K-Means with all the features\n", "Run K-Means using all the features available and visualise the result in the subspace `mean_spent` and `max_spent`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Apply k-means with 2 clusters using all features\n", "kmeans = KMeans(n_clusters = 2)\n", "kmeans.fit(customers)\n", "cluster_assignment = kmeans.predict(customers)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["and visualise using the same subset of variables as before... what has changed??"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualise the clusters using pairplot_cluster()\n", "pairplot_cluster(customers, ['mean_spent', 'max_spent'], cluster_assignment)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***Question***: Why can't the clusters be separated with a line as before?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Learning activity - Compare expenditure between clusters\n", "\n", "Select the features `'mean_spent'` and `'max_spent'` and compare the two clusters obtained above using them."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compare expenditure between clusters\n", "features = ['mean_spent', 'max_spent']\n", "\n", "# create a dataframe corresponding to the case\n", "# cluster_assignment == 0\n", "cluster1_df = pd.DataFrame(data= customers[cluster_assignment == 0], \n", "                             columns=customers.columns)[features]\n", "\n", "cluster1_desc = cluster1_df.describe()\n", "cluster1_desc.columns = [c+'_0' for c in cluster1_desc.columns]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# then with cluster_assignment == 0\n", "cluster2_df = pd.DataFrame(data=customers[cluster_assignment == 1], \n", "                             columns=customers.columns)[features]\n", "\n", "cluster2_desc = cluster2_df.describe()\n", "cluster2_desc.columns = [c+'_1' for c in cluster2_desc.columns]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Concatenate both:\n", "compare_df = pd.concat((cluster1_desc, cluster2_desc), axis=1)\n", "compare_df\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Test Activity - Looking at the centroids\n", "\n", "Look at the centroids of the clusters `kmeans.cluster_centers_` and check the values of the centroids for the features `mean_spent`, `max_spent`. You will need to create a new DataFrame where the data is simply `kmeans.cluster_centers_`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get the centroids and display them\n", "centers_df = pd.DataFrame(data=kmeans.cluster_centers_, columns=customers.columns)\n", "print(centers_df[features])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Learning Activity - Compare mean expediture with box plot\n", "\n", "Compare the distribution of the feature `mean_spent` in the two clusters using a box plot. You will need:\n", "\n", "* `sns.boxplot` (seaborn's boxplot)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compare mean expediture with box plot\n", "cluster1_df.columns = [c+'_0' for c in cluster1_df.columns]\n", "cluster2_df.columns = [c+'_1' for c in cluster2_df.columns]\n", "\n", "#plt.figure(figsize = (10,6))\n", "sns.boxplot(data=pd.concat((cluster1_desc['mean_spent_0'], \n", "                            cluster2_desc['mean_spent_1']), \n", "                           axis=1), showfliers=False)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["does this seem to make sense? How can you interpret the plots?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Learning Activity - Compute the silhouette score\n", "Compute the silhouette score of the clusters resuting from the application of K-Means.\n", "\n", "The Silhouette Coefficient is calculated using the mean intra-cluster distance (``a``) and the mean nearest-cluster distance (``b``) for each sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a, b)``. It represents how similar a sample is to the samples in its own cluster compared to samples in other clusters.\n", "\n", "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n", "\n", "`sklearn` provides the function `silhouette_score` which you can call and display."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import silhouette_score\n", "\n", "# Computing the silhouette score\n", "print('silhouette_score {0:.2f}'.format(silhouette_score(customers, cluster_assignment)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This silhouette score is reasonably high which we can intepret by saying that the corresponding clusters are quite compact."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Test Activity - Run KMeans on the dataset obtained with PCA\n", "\n", "Compute KMeans on the dataset `XScores` using the first 2 principal components.\n", "\n", "Visualise the results using again the function `pairplot_cluster` in the first 4 principal components."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run KMeans on the first two principal components\n", "kmeans = KMeans(n_clusters = 2)\n", "kmeans.fit(Xscores[['PC1', 'PC2']])\n", "cluster_assignment = kmeans.predict(Xscores[['PC1', 'PC2']])\n", "pairplot_cluster(Xscores, ['PC1', 'PC2', 'PC3', 'PC4'], cluster_assignment)\n"]}]}